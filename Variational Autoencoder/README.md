This folder contains implementation of [Variational Autoencoder](https://arxiv.org/pdf/1312.6114.pdf)

This code also uses [Residual Networks](https://arxiv.org/pdf/1512.03385.pdf) & Inverse Residual Networks to obtain good results. 

There are two .ipynb files(Jupyter Notebooks), which can be used as an alternative if you have any problem in running .py files

Type the below command in your terminal to train the model

```
python train.py
```

After training: 

![](https://i.imgur.com/RGoMAZR.png)

Results

First row is original MNIST images
Second row is reconstructed image

![](https://i.imgur.com/a5suZ66.png)

Randomly generated image. The latent of the image is generated by taking mean of latent vectors of 10 images which belongs to class "5"

![](https://i.imgur.com/Hb6OhDf.png)



Mathematical understanding of Variational Autoencoder is simplified [here](https://github.com/AndrewSpano/Disentangled_Variational_Autoencoder/blob/main/mathematical_analysis/vae_maths.pdf)

Lecture by Prof. Ali Ghodsi [Video Lecture](https://www.youtube.com/watch?v=uaaqyVS9-rM&t=1235s)

P.S: 5 epochs are enough to get good results( as it's MNIST). And it hardly takes 5-10 minutes for completing the 5 epochs
